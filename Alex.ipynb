{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet was first proposed was Alex Krizhevsky et al. and was the winner of\n",
    "# ImageNet large-scale visual recognition challenge (ILSVRC) in 2012. It is\n",
    "# composed of five convolutional layers and three fully connected layers. Max-\n",
    "# pooling layers follow both resopnse normalization layers and the fifth\n",
    "# convolutional layer.\n",
    "\n",
    "# We use the version of AlexNet found at:\n",
    "# https://github.com/tensorflow/models/tree/master/research/slim/nets\n",
    "# We reproduce it with some modifications in accordance with \n",
    "# http://www.apache.org/licenses/LICENSE-2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "trunc_normal = lambda stddev: tf.truncated_normal_initializer(0.0, stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_v2_arg_scope(weight_decay=0.0005):\n",
    "  with slim.arg_scope([slim.conv2d, slim.fully_connected],\n",
    "                      activation_fn=tf.nn.relu,\n",
    "                      biases_initializer=tf.constant_initializer(0.1),\n",
    "                      weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "    with slim.arg_scope([slim.conv2d], padding='SAME'):\n",
    "      with slim.arg_scope([slim.max_pool2d], padding='VALID') as arg_sc:\n",
    "        return arg_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet_v2(inputs,\n",
    "               num_classes=1000,\n",
    "               is_training=True,\n",
    "               dropout_keep_prob=0.5,\n",
    "               spatial_squeeze=True,\n",
    "               scope='alexnet_v2',\n",
    "               global_pool=False):\n",
    "  \"\"\"AlexNet version 2.\n",
    "  Described in: http://arxiv.org/pdf/1404.5997v2.pdf\n",
    "  Parameters from:\n",
    "  github.com/akrizhevsky/cuda-convnet2/blob/master/layers/\n",
    "  layers-imagenet-1gpu.cfg\n",
    "  Note: All the fully_connected layers have been transformed to conv2d layers.\n",
    "        To use in classification mode, resize input to 224x224 or set\n",
    "        global_pool=True. To use in fully convolutional mode, set\n",
    "        spatial_squeeze to false.\n",
    "        The LRN layers have been removed and change the initializers from\n",
    "        random_normal_initializer to xavier_initializer.\n",
    "  Args:\n",
    "    inputs: a tensor of size [batch_size, height, width, channels].\n",
    "    num_classes: the number of predicted classes. If 0 or None, the logits layer\n",
    "    is omitted and the input features to the logits layer are returned instead.\n",
    "    is_training: whether or not the model is being trained.\n",
    "    dropout_keep_prob: the probability that activations are kept in the dropout\n",
    "      layers during training.\n",
    "    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n",
    "      logits. Useful to remove unnecessary dimensions for classification.\n",
    "    scope: Optional scope for the variables.\n",
    "    global_pool: Optional boolean flag. If True, the input to the classification\n",
    "      layer is avgpooled to size 1x1, for any input size. (This is not part\n",
    "      of the original AlexNet.)\n",
    "  Returns:\n",
    "    net: the output of the logits layer (if num_classes is a non-zero integer),\n",
    "      or the non-dropped-out input to the logits layer (if num_classes is 0\n",
    "      or None).\n",
    "    end_points: a dict of tensors with intermediate activations.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope(scope, 'alexnet_v2', [inputs]) as sc:\n",
    "    end_points_collection = sc.original_name_scope + '_end_points'\n",
    "    # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                        outputs_collections=[end_points_collection]):\n",
    "      net = slim.conv2d(inputs, 64, [11, 11], 4, padding='VALID',\n",
    "                        scope='conv1')\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
    "      net = slim.conv2d(net, 192, [5, 5], scope='conv2')\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "      net = slim.conv2d(net, 384, [3, 3], scope='conv3')\n",
    "      net = slim.conv2d(net, 384, [3, 3], scope='conv4')\n",
    "      net = slim.conv2d(net, 256, [3, 3], scope='conv5')\n",
    "      net = slim.max_pool2d(net, [3, 3], 2, scope='pool5')\n",
    "\n",
    "      # Use conv2d instead of fully_connected layers.\n",
    "      with slim.arg_scope([slim.conv2d],\n",
    "                          weights_initializer=trunc_normal(0.005),\n",
    "                          biases_initializer=tf.constant_initializer(0.1)):\n",
    "        net = slim.conv2d(net, 4096, [5, 5], padding='VALID',\n",
    "                          scope='fc6')\n",
    "        net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                           scope='dropout6')\n",
    "        net = slim.conv2d(net, 4096, [1, 1], scope='fc7')\n",
    "        # Convert end_points_collection into a end_point dict.\n",
    "        end_points = slim.utils.convert_collection_to_dict(\n",
    "            end_points_collection)\n",
    "        if global_pool:\n",
    "          net = tf.reduce_mean(net, [1, 2], keep_dims=True, name='global_pool')\n",
    "          end_points['global_pool'] = net\n",
    "        if num_classes:\n",
    "          net = slim.dropout(net, dropout_keep_prob, is_training=is_training,\n",
    "                             scope='dropout7')\n",
    "          net = slim.conv2d(net, num_classes, [1, 1],\n",
    "                            activation_fn=None,\n",
    "                            normalizer_fn=None,\n",
    "                            biases_initializer=tf.zeros_initializer(),\n",
    "                            scope='fc8')\n",
    "          if spatial_squeeze:\n",
    "            net = tf.squeeze(net, [1, 2], name='fc8/squeezed')\n",
    "          end_points[sc.name + '/fc8'] = net\n",
    "      return net, end_points\n",
    "alexnet_v2.default_image_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
